{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jtp2PTNR1c6e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"train.csv\", encoding='unicode_escape')\n",
        "df_train[\"content\"] = df_train[\"text\"]\n",
        "df_test = pd.read_csv(\"FINAL_merged_formatted_Amazon_Bestsellers_ALL_Reviews.csv\")\n",
        "df_train['content'] = df_train['content'].astype(str)\n",
        "df_test['content'] = df_test['content'].astype(str)"
      ],
      "metadata": {
        "id": "ykz0wAD07Vqi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train set length:\", len(df_train))\n",
        "print(\"Web set length:\", len(df_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdZTZg0o7zf9",
        "outputId": "f7cadafc-5f7a-48c5-b938-7618abf7112f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set length: 27481\n",
            "Web set length: 33468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Partitioning"
      ],
      "metadata": {
        "id": "fn9R8Buj-XVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def partition(x):\n",
        "    if x == \"negative\":\n",
        "        return 0\n",
        "    elif x == \"neutral\":\n",
        "        return 2\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "actualScore = df_train['sentiment']\n",
        "class_ = actualScore.map(partition)\n",
        "df_train['ratings_class'] = class_\n",
        "df_train.ratings_class.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0vUS5Ey-Skd",
        "outputId": "0fe4ae46-d9f5-4886-f7d8-c2ac79878f3e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ratings_class\n",
              "2    11118\n",
              "1     8582\n",
              "0     7781\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def partition(x):\n",
        "    if x < 3:\n",
        "        return 2\n",
        "    elif x == 3:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "# actualScore = df_test['rating']\n",
        "# class_ = actualScore.map(partition)\n",
        "# df_test['ratings_class'] = class_\n",
        "# df_test.ratings_class.value_counts()"
      ],
      "metadata": {
        "id": "n2D9sd-SDLLU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stemming"
      ],
      "metadata": {
        "id": "UdvojKQU8Gg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p3VUrMu8EMF",
        "outputId": "9dee77b9-7dfc-482d-f7cf-dd367b8e12b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming(x):\n",
        "    stemmer = PorterStemmer()\n",
        "    x = word_tokenize(x)\n",
        "    output = ''\n",
        "\n",
        "    for i in x:\n",
        "        output += stemmer.stem(i) + ' '\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "X9Szmzjq8I6R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['content'] = df_train['content'].apply(stemming)\n",
        "df_test['content'] = df_test['content'].apply(stemming)"
      ],
      "metadata": {
        "id": "c69hFxmI8KYL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemmatization"
      ],
      "metadata": {
        "id": "YXRVMcvi8bJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W_MZ6p18dLk",
        "outputId": "a9460a10-eff6-4724-fdcf-1440a4841a2b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "def get_lemmatized_text(corpus):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]"
      ],
      "metadata": {
        "id": "jk3tZN7j8fBD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['content'] = get_lemmatized_text(df_train['content'])\n",
        "df_test['content'] = get_lemmatized_text(df_test['content'])"
      ],
      "metadata": {
        "id": "u_Q0K2zg8gcV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removal of Stopwords"
      ],
      "metadata": {
        "id": "zkV973MR8nQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop = stopwords.words('english')\n",
        "additional_stopwords = [\"'s\",\"...\",\"'ve\",\"``\",\"''\",\"'m\",'--',\"'ll\",\"'d\"]\n",
        "stop = set(stop + additional_stopwords)\n",
        "def remove_stop(x):\n",
        "    x = word_tokenize(x)\n",
        "    store = ''\n",
        "\n",
        "    for i in x:\n",
        "        if i not in stop:\n",
        "            store += i + ' '\n",
        "\n",
        "    return store"
      ],
      "metadata": {
        "id": "857p2Hzp8mxk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['content'] = df_train['content'].apply(remove_stop)\n",
        "df_test['content'] = df_test['content'].apply(remove_stop)"
      ],
      "metadata": {
        "id": "srpbWAjt8qx_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wordcount"
      ],
      "metadata": {
        "id": "5EW2M2-L8-ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wordcount = df_train['content'].apply(lambda x: len(x.split())).sum()\n",
        "print(\"There are {} words in the corpus.\".format(wordcount))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtTzMbag84AH",
        "outputId": "c13ef853-2b18-42f7-b8f2-94a1fb382a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 274428 words in the corpus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.content.str.split(expand=True).stack().value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSUvKN5m88fC",
        "outputId": "a4b0594c-15e2-44fb-bfcf-d33bcc1379aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "!                       15296\n",
              ".                       13910\n",
              "`                       11614\n",
              ",                        8461\n",
              "*                        4953\n",
              "                        ...  \n",
              "kaila                       1\n",
              "//tinyurl.com/64ozr7        1\n",
              "weeaboo                     1\n",
              "boo-hoo                     1\n",
              "atg                         1\n",
              "Name: count, Length: 23257, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes Classification"
      ],
      "metadata": {
        "id": "2289cM2M9DR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import time\n",
        "\n",
        "x_train, x_test, y_train = df_train[[\"content\"]], df_test[[\"content\"]], \\\n",
        "        df_train[\"ratings_class\"]\n",
        "\n",
        "start_time = time.time()\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=True, sublinear_tf=True)\n",
        "comment_matrix = vectorizer.fit_transform(x_train['content'])\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "comment_classifier = MultinomialNB().fit(comment_matrix, y_train)\n",
        "print(\"--- Training time: %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "from sklearn import metrics\n",
        "test_vector = vectorizer.transform(x_test['content'])\n",
        "\n",
        "start_time = time.time()\n",
        "result = comment_classifier.predict(test_vector)\n",
        "print(\"--- Evaluating time: %s seconds ---\" % (time.time() - start_time))\n",
        "result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgbJI37c9EsU",
        "outputId": "846f1332-ad96-432a-c0e2-5e2c2bc086de"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training time: 0.6495673656463623 seconds ---\n",
            "--- Evaluating time: 0.009547948837280273 seconds ---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 2, ..., 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test[\"model_prediction\"] = result\n",
        "df_test[\"model_prediction\"] = df_test[\"model_prediction\"].replace({1: 'positive', 0: 'negative', 2: 'neutral'})"
      ],
      "metadata": {
        "id": "Sr1fpFgAIOds"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.to_csv(\"NB_model_prediction.csv\")"
      ],
      "metadata": {
        "id": "dbDB4XxOIooc"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}